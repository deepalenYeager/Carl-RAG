{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install markitdown   \n",
    "This is an open-source package for converting PDF to MarkDown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markitdown import MarkItDown\n",
    "\n",
    "md = MarkItDown()\n",
    "result = md.convert(\"data/2024全球经济金融展望报告.pdf\")\n",
    "with open(\"data/md_file.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result.text_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all page content into one string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.schema import Document\n",
    "import re\n",
    "\n",
    "loader = PyPDFLoader(\"data/2024全球经济金融展望报告.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "### documents is a list where each element is a Document object, which respresenting each page of content loaded from  the PDF document.\n",
    "pattern = r\"^全球经济金融展望报告\\n中国银行研究院 \\d+ 2024年\"\n",
    "merged_docs = [Document(page_content='\\n'.join(re.sub(pattern, '', doc.page_content) for doc in documents))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from uuid import uuid4\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_docs(documents, filepath, chunk_size=400, chunk_overlap=40, seperators=['\\n\\n\\n', '\\n\\n'], force_split=False):\n",
    "    if os.path.exists(filepath) and not force_split:\n",
    "        print('found cache, restoring...')\n",
    "        return pickle.load(open(filepath, 'rb'))\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=seperators\n",
    "    )\n",
    "    split_docs = splitter.split_documents(documents)\n",
    "    for chunk in split_docs:\n",
    "        chunk.metadata['uuid'] = str(uuid4())\n",
    "\n",
    "    pickle.dump(split_docs, open(filepath, 'wb'))\n",
    "\n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_docs = split_docs(documents, os.path.join(\"outputs\", 'split_docs.pkl'), chunk_size=500, chunk_overlap=50)\n",
    "splitted_docs_large = split_docs(merged_docs, os.path.join(\"outputs\", 'split_docs_large.pkl'), chunk_size=1500, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_gen_prompt_tmpl = \"\"\"\n",
    "我会给你一段文本（<document></document>之间的部分），你需要阅读这段文本，分别针对这段文本生成8个问题、用户回答这个问题的上下文，和基于上下文对问题的回答。\n",
    "\n",
    "对问题、上下文、答案的要求：\n",
    "\n",
    "问题要与这段文本相关，不要询问类似“这个问题的答案在哪一章”这样的问题\n",
    "上下文：上下文必须与原始文本的内容保持一致，不要进行缩写、扩写、改写、摘要、替换词语等\n",
    "答案：回答请保持完整且简洁，无须重复问题。答案要能够独立回答问题，而不是引用现有的章节、页码等\n",
    "\n",
    "返回结果以JSON形式组织，格式为[{\"question\": \"...\", \"context\": ..., \"answer\": \"...\"}, ...]。\n",
    "如果当前文本主要是目录，或者是一些人名、地址、电子邮箱等没有办法生成有意义的问题时，可以返回[]。\n",
    "\n",
    "下方是文本：\n",
    "<document>\n",
    "{{document}}\n",
    "</document>\n",
    "\n",
    "请生成结果：\n",
    "\"\"\"\n",
    "\n",
    "qa_gen_prompt_tmpl_large_context = \"\"\"\n",
    "我会给你一段文本（<document></document>之间的部分），你需要阅读这段文本，分别针对这段文本生成2个问题，和基于这段文本对问题的回答，回答请保持完整，无须重复问题。\n",
    "尽可能创建一些需要综合*大段*文本才能回答的问题，但不要问类似“这一段主要讲了什么内容”这样的问题，答案要能够独立回答问题，而不是引用现有的章节、页码等；不要问具体过于细节的问题，例如“海湾国家的2024年预期经济增长率是多少”，而是尽可能问类似“2024年全球经济的几大趋势是什么”、“受局部中东地区紧张局势影响，可能对全球原物料有哪些影响”。\n",
    "返回结果以JSON形式组织，格式为[{\"question\": \"...\", \"answer\": \"...\"}, ...]。\n",
    "如果当前文本主要是目录，或者是一些人名、地址、电子邮箱等没有办法生成有意义的问题时，可以返回[]。\n",
    "\n",
    "下方是文本：\n",
    "<document>\n",
    "{{document}}\n",
    "</document>\n",
    "\n",
    "请生成结果：\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "import random\n",
    "\n",
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI(api_key=\"\")  \n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"glm-4-plus\",  \n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"你是一个乐于回答各种问题的小助手，你的任务是提供专业、准确、有洞察力的建议。\"},\n",
    "#         {\"role\": \"user\", \"content\": \"你是谁\"},\n",
    "#     ],\n",
    "#     stream=True,\n",
    "# )\n",
    "# for chunk in response:\n",
    "#     print(chunk.choices[0].delta.content)\n",
    "\n",
    "def build_qa_prompt(prompt_tmpl, text):\n",
    "    prompt = prompt_tmpl.replace('{{document}}', text).strip()\n",
    "    return prompt\n",
    "\n",
    "def chat(prompt, max_retry=3, debug=False, top_p=0.95, temperature=0.85):\n",
    "    def do_chat(prompt):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"glm-4-plus\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"你是一个乐于回答各种问题的小助手，你的任务是提供专业、准确、有洞察力的建议。\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            top_p=top_p,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "    while max_retry > 0:\n",
    "        try:\n",
    "            return do_chat(prompt)\n",
    "        except Exception as e:\n",
    "            max_retry -= 1\n",
    "            sleep_seconds = random.randint(1, 4)\n",
    "            if debug:\n",
    "                print(f\"{str(e)}, remain retry: {max_retry}, sleeping {sleep_seconds}s {prompt}\")\n",
    "            time.sleep(sleep_seconds)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存到 output.jsonl 文件中。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import io\n",
    "import json\n",
    "\n",
    "# 读取Markdown文件\n",
    "with open('data/6. 特高压直流测量设备关键点技术监督实施细则.md', 'r', encoding='utf-8') as file:\n",
    "    markdown_text = file.read()\n",
    "\n",
    "# 提取表格部分\n",
    "table_pattern = re.compile(r'\\|.*\\|\\n\\|.*\\|\\n(\\|.*\\|\\n)*')  # 匹配Markdown表格\n",
    "table_match = table_pattern.search(markdown_text)\n",
    "\n",
    "if table_match:\n",
    "    table_text = table_match.group(0)\n",
    "    # 将Markdown表格转换为Pandas DataFrame\n",
    "    df = pd.read_csv(io.StringIO(table_text), sep='|', header=0, skipinitialspace=True)\n",
    "    df = df.dropna(axis=1, how='all')  # 删除空列\n",
    "    df.columns = df.columns.str.strip()  # 清理列名\n",
    "\n",
    "    # 将每一行提取为JSON对象\n",
    "    with open('output.jsonl', 'w', encoding='utf-8') as json_file:\n",
    "        for _, row in df.iterrows():\n",
    "            row_dict = row.to_dict()\n",
    "            json_file.write(json.dumps(row_dict, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    print(\"数据已保存到 output.jsonl 文件中。\")\n",
    "else:\n",
    "    print(\"未找到Markdown表格。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "修改后的数据已保存到 modified_output.jsonl 文件中。\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 定义键名称映射\n",
    "key_mapping = {\n",
    "    \"特高压直流测量设备关键点技术监督实施细则\": \"特高压直流测量设备关键点技术监督实施细则 序号\",\n",
    "    \"工程名称\": \"监督项目\",\n",
    "    \"Unnamed: 3\": \"监督标准\",\n",
    "    \"生产厂家\": \"监督性质\",\n",
    "    \"Unnamed: 5\": \"监督方式\",\n",
    "    \"Unnamed: 6\": \"监督出处\",\n",
    "    \"Unnamed: 7\": \"监督结论\",\n",
    "    \"Unnamed: 8\": \"监督单位\",\n",
    "    \"Unnamed: 9\": \"问题说明\"\n",
    "}\n",
    "\n",
    "# 读取原始JSONL文件\n",
    "input_file = 'output.jsonl'\n",
    "output_file = 'modified_output.jsonl'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    for line in infile:\n",
    "        # 解析JSON对象\n",
    "        data = json.loads(line.strip())\n",
    "        \n",
    "        # 修改键名称\n",
    "        modified_data = {key_mapping.get(k, k): v for k, v in data.items()}\n",
    "        \n",
    "        # 写入新的JSONL文件\n",
    "        outfile.write(json.dumps(modified_data, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"修改后的数据已保存到 {output_file} 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_jsonl(input_file, output_file):\n",
    "    # 读取JSONL文件\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "    # 解析JSONL文件\n",
    "    json_list = [json.loads(line) for line in lines]\n",
    "\n",
    "    # 创建一个字典来存储每个主序号的\"监督项目\"值\n",
    "    main_supervision_dict = {}\n",
    "\n",
    "    # 第一次遍历：收集所有主序号的\"监督项目\"值\n",
    "    for json_obj in json_list:\n",
    "        key = json_obj.get(\"测量设备基础信息 序号\")\n",
    "        if isinstance(key, str):\n",
    "            # 提取主序号（如 \"1.1\" 的主序号是 \"1\"）\n",
    "            main_key = key.split('.')[0]\n",
    "            if '.' not in key:  # 如果当前是主序号（如 \"1\", \"2\" 等）\n",
    "                main_supervision_dict[main_key] = json_obj.get(\"监督项目\", \"\")\n",
    "\n",
    "    # 第二次遍历：更新所有子序号的\"监督项目\"值\n",
    "    for json_obj in json_list:\n",
    "        key = json_obj.get(\"测量设备基础信息 序号\")\n",
    "        if isinstance(key, str):\n",
    "            # 提取主序号\n",
    "            main_key = key.split('.')[0]\n",
    "            if '.' in key:  # 如果当前是子序号（如 \"1.1\", \"2.1\" 等）\n",
    "                main_supervision = main_supervision_dict.get(main_key, \"\")\n",
    "                json_obj[\"监督项目\"] = main_supervision + json_obj.get(\"监督项目\", \"\")\n",
    "\n",
    "    # 将处理后的JSON对象写回到新的JSONL文件\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for json_obj in json_list:\n",
    "            outfile.write(json.dumps(json_obj, ensure_ascii=False) + '\\n')\n",
    "\n",
    "# 示例调用\n",
    "input_file = 'modified_output.jsonl'\n",
    "output_file = 'modified_output_.jsonl'\n",
    "process_jsonl(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
